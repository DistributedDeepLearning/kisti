{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mf:\\kisti\\DistributedDataParallel_example.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/kisti/DistributedDataParallel_example.ipynb#ch0000000?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/kisti/DistributedDataParallel_example.ipynb#ch0000000?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/kisti/DistributedDataParallel_example.ipynb#ch0000000?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmodel\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mbaseline\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/kisti/DistributedDataParallel_example.ipynb#ch0000000?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m \u001b[39mimport\u001b[39;00m transforms\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/kisti/DistributedDataParallel_example.ipynb#ch0000000?line=7'>8</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_train_loader\u001b[39m(image_size, batch_size, num_worker):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'model'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import model as baseline\n",
    " \n",
    "from torchvision import transforms\n",
    " \n",
    "def get_train_loader(image_size, batch_size, num_worker):\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(image_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomRotation(45),\n",
    "        transforms.RandomAffine(45),\n",
    "        transforms.ColorJitter(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])])\n",
    "    train_datasets = torchvision.datasets.ImageFolder(\n",
    "        root=f'data/test', transform=transform_train)\n",
    "    train_sampler = torch.utils.data.distributed.DistributedSampler(train_datasets)\n",
    "    shuffle = False\n",
    "    pin_memory = True\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_datasets, batch_size=batch_size, pin_memory=pin_memory,\n",
    "        num_workers=num_worker, shuffle=shuffle, sampler=train_sampler)\n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    ngpus_per_node = torch.cuda.device_count()\n",
    "    world_size = ngpus_per_node\n",
    " \n",
    "    torch.multiprocessing.spawn(main_worker, nprocs=ngpus_per_node, args=(ngpus_per_node, ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_worker(gpu, ngpus_per_node):\n",
    "     \n",
    "    image_size = 224\n",
    "    batch_size = 512\n",
    "    num_worker = 8\n",
    "    epochs = 1\n",
    " \n",
    "    batch_size = int(batch_size / ngpus_per_node)\n",
    "    num_worker = int(num_worker / ngpus_per_node)\n",
    "    \n",
    "    torch.distributed.init_process_group(\n",
    "            backend='nccl',\n",
    "            init_method='tcp://127.0.0.1:3456',\n",
    "            world_size=ngpus_per_node,\n",
    "            rank=gpu)\n",
    "    model = baseline.ResnetModel()\n",
    "    torch.cuda.set_device(gpu)\n",
    "    model = model.cuda(gpu)\n",
    "    model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[gpu])\n",
    " \n",
    "    train_loader = get_train_loader(\n",
    "        image_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "        num_worker=num_worker)\n",
    " \n",
    "    optimizer = torch.optim.SGD(\n",
    "        params=model.parameters(),\n",
    "        lr=0.001,\n",
    "        momentum=0.9)\n",
    "    criterion = torch.nn.CrossEntropyLoss().to(gpu)\n",
    " \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    " \n",
    "        start_time = time.time()\n",
    "        for j, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(gpu), labels.to(gpu)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            logits, _, _ = model(images)\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    " \n",
    " \n",
    "            print(f'epoch : {epoch} | step : {j} / {len(train_loader)} | mp : {gpu}')\n",
    "        end_time = time.time()\n",
    "        print('total time :', end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.8",
   "language": "python",
   "name": "tf2.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
